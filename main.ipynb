{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T15:15:32.737935Z",
     "start_time": "2019-03-17T15:15:30.513669Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T15:15:33.755224Z",
     "start_time": "2019-03-17T15:15:33.748243Z"
    }
   },
   "outputs": [],
   "source": [
    "NOISE_SHAPE = (1, 1, 100)\n",
    "IMAGE_SIZE = 64\n",
    "ADAM_BETA = 0.5\n",
    "BATCH_SIZE = 64\n",
    "LABEL_NOISE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T15:15:38.045176Z",
     "start_time": "2019-03-17T15:15:34.264394Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disc_opt = Adam(lr=0.0002, beta_1=ADAM_BETA)\n",
    "gen_opt = Adam(lr=0.0001, beta_1=ADAM_BETA)\n",
    "\n",
    "# BUILD GENERATOR\n",
    "gen = build_generator(NOISE_SHAPE)\n",
    "gen.compile(optimizer=gen_opt, loss='binary_crossentropy')\n",
    "\n",
    "# BUILD DISCRIMINATOR\n",
    "input_shape = (IMAGE_SIZE,IMAGE_SIZE,4)\n",
    "disc = build_discriminator(input_shape)\n",
    "disc.compile(optimizer=disc_opt, loss='binary_crossentropy')\n",
    "\n",
    "# BUILD GAN(GENERATOR+DISCRIMINATOR)\n",
    "noise = Input(shape=NOISE_SHAPE)\n",
    "gened = gen(noise)\n",
    "result = disc(gened)\n",
    "gan = models.Model(inputs=noise, outputs=result)\n",
    "gan.compile(optimizer=gen_opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T14:40:02.275504Z",
     "start_time": "2019-03-17T14:40:02.270549Z"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T15:15:52.542791Z",
     "start_time": "2019-03-17T15:15:38.046931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path to the folder with input images\n",
    "INPUT_DATA_DIR = \"A:\\\\datasets\\\\all_pokemons\\\\pokemon\\\\\"\n",
    "\n",
    "# convert all images from INPUT_DATA_DIR to array with shape [819,64,64,4]\n",
    "input_images = np.asarray([\n",
    "    np.asarray(Image.open(file).resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    for file in glob(INPUT_DATA_DIR + '*')\n",
    "])\n",
    "input_images = normalize(input_images)\n",
    "\n",
    "for batch in range(1):\n",
    "    print('BATCH:{}'.format(batch))\n",
    "    # fake labels for discriminator in range [0,0.1]\n",
    "    fake_labels = LABEL_NOISE * np.random.ranf(BATCH_SIZE)\n",
    "    # real labels for discriminator in range [0.9,1]\n",
    "    real_labels = 1 - LABEL_NOISE * np.random.ranf(BATCH_SIZE)\n",
    "\n",
    "    \n",
    "    fakes, noises = sample_fake(gen,BATCH_SIZE,NOISE_SHAPE)\n",
    "    reals = sample_faces(input_images,BATCH_SIZE)\n",
    "    \n",
    "    #add noises to real image\n",
    "    reals += 0.5 * np.exp(-batch / 100) * np.random.normal(size=reals.shape)\n",
    "\n",
    "    # train discriminator,without generator\n",
    "    gen.trainable = False\n",
    "    d_loss1 = disc.train_on_batch(reals, real_labels)\n",
    "    d_loss0 = disc.train_on_batch(fakes, fake_labels)\n",
    "    gen.trainable = True\n",
    "\n",
    "    # train generator, without discriminator\n",
    "    disc.trainable = False\n",
    "    g_loss = gan.train_on_batch(noises, real_labels)\n",
    "    disc.trainable = True\n",
    "\n",
    "\n",
    "    # save weights every 500 batches\n",
    "    if batch % 500 == 0:\n",
    "        noise = make_noise(BATCH_SIZE,NOISE_SHAPE)\n",
    "        frame = gen.predict(noise)\n",
    "        if os.path.exists('./test_images'): \n",
    "            grid_image_size = 8\n",
    "            save_images(\n",
    "                denormalize(frame), [grid_image_size,grid_image_size],\n",
    "                './test_images/' + str(batch) + '.png')\n",
    "        else:\n",
    "            os.mkdir('./test_images')\n",
    "\n",
    "        if os.path.exists('./weights'): \n",
    "            gen.save_weights('./weights/' + str(batch) + \"_gen.hdf5\")\n",
    "            disc.save_weights('./weights/' + str(batch) + \"_disc.hd5f\")\n",
    "        else:\n",
    "            os.mkdir('./weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T15:15:53.230949Z",
     "start_time": "2019-03-17T15:15:52.545782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen.load_weights('./weights/pretrained_generator.hdf5')\n",
    "noise = make_noise(1,NOISE_SHAPE)\n",
    "predictions = gen.predict(noise)\n",
    "predictions = np.squeeze(denormalize(predictions))\n",
    "imgplot = plt.imshow(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
